{"timestamp": "2025-12-27T05:51:09.905673", "claim": "Bitcoin was invented in 2009", "verdict": "Verified", "confidence_score": 0.95, "tokens": {"total_input": 4850, "total_output": 370, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 1200, "output": 150}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 1150, "output": 140}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 2500, "output": 80}}, "costs": {"prover_cost": 0.000826, "debunker_cost": 0.000465, "judge_cost": 0.0029, "total_cost": 0.004191}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.004191, "profit_usd": 0.045809, "profit_margin_pct": 91.62}, "metadata": {"search_count": 10, "execution_time_sec": 8.5}}
{"timestamp": "2025-12-27T05:51:09.906338", "claim": "The sky is blue", "verdict": "Verified", "confidence_score": 0.98, "tokens": {"total_input": 3350, "total_output": 250, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 800, "output": 100}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 750, "output": 90}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1800, "output": 60}}, "costs": {"prover_cost": 0.000551, "debunker_cost": 0.000302, "judge_cost": 0.0021, "total_cost": 0.002952}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002952, "profit_usd": 0.047048, "profit_margin_pct": 94.1}, "metadata": {"search_count": 8, "execution_time_sec": 6.2}}
{"timestamp": "2025-12-27T05:51:09.906796", "claim": "Will it rain tomorrow in New York?", "verdict": "Uncertain", "confidence_score": 0.65, "tokens": {"total_input": 6100, "total_output": 480, "prover": {"model": "gemini-2.0-flash-exp", "input": 1500, "output": 200}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 1400, "output": 180}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 3200, "output": 100}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.0037, "total_cost": 0.0037}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.0037, "profit_usd": 0.0463, "profit_margin_pct": 92.6}, "metadata": {"search_count": 12, "execution_time_sec": 12.3}}
{"timestamp": "2025-12-30T19:45:54.305386", "claim": "Is Rihanna the founder of Fenty Beauty?", "verdict": "Verified", "confidence_score": 0.85, "tokens": {"total_input": 3131, "total_output": 505, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 820, "output": 105}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 856, "output": 139}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1455, "output": 261}}, "costs": {"prover_cost": 0.000567, "debunker_cost": 0.000384, "judge_cost": 0.00276, "total_cost": 0.003711}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003711, "profit_usd": 0.046289, "profit_margin_pct": 92.58}, "metadata": {"search_count": 5, "execution_time_sec": 16.46}}
{"timestamp": "2025-12-30T19:46:44.319337", "claim": "The Earth orbits the Sun", "verdict": "Verified", "confidence_score": 0.95, "tokens": {"total_input": 2874, "total_output": 478, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 761, "output": 130}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 790, "output": 90}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1323, "output": 258}}, "costs": {"prover_cost": 0.000552, "debunker_cost": 0.000312, "judge_cost": 0.002613, "total_cost": 0.003477}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003477, "profit_usd": 0.046523, "profit_margin_pct": 93.05}, "metadata": {"search_count": 5, "execution_time_sec": 13.89}}
{"timestamp": "2025-12-30T19:54:26.788653", "claim": "Is Jesus the son of God?", "verdict": "Inconclusive", "confidence_score": 0.35, "tokens": {"total_input": 2936, "total_output": 373, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 810, "output": 112}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 809, "output": 87}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1317, "output": 174}}, "costs": {"prover_cost": 0.000566, "debunker_cost": 0.000314, "judge_cost": 0.002187, "total_cost": 0.003068}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003068, "profit_usd": 0.046932, "profit_margin_pct": 93.86}, "metadata": {"search_count": 5, "execution_time_sec": 15.27}}
{"timestamp": "2025-12-30T20:00:37.625816", "claim": "Is Jesus the son of God?", "verdict": "Inconclusive", "confidence_score": 0.45, "tokens": {"total_input": 3075, "total_output": 482, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 825, "output": 120}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 828, "output": 117}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1422, "output": 245}}, "costs": {"prover_cost": 0.000582, "debunker_cost": 0.000352, "judge_cost": 0.002647, "total_cost": 0.003581}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003581, "profit_usd": 0.046419, "profit_margin_pct": 92.84}, "metadata": {"search_count": 5, "execution_time_sec": 15.42}}
{"timestamp": "2025-12-30T20:02:34.333154", "claim": "Is Jesus the son of God?", "verdict": "Inconclusive", "confidence_score": 0.65, "tokens": {"total_input": 3204, "total_output": 517, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 842, "output": 114}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 886, "output": 112}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1476, "output": 291}}, "costs": {"prover_cost": 0.000587, "debunker_cost": 0.000362, "judge_cost": 0.002931, "total_cost": 0.00388}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.00388, "profit_usd": 0.04612, "profit_margin_pct": 92.24}, "metadata": {"search_count": 5, "execution_time_sec": 24.38}}
{"timestamp": "2025-12-30T20:04:43.238398", "claim": "Is Jesus the son of God?", "verdict": "Inconclusive", "confidence_score": 0.55, "tokens": {"total_input": 3012, "total_output": 471, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 811, "output": 113}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 825, "output": 108}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1376, "output": 250}}, "costs": {"prover_cost": 0.000568, "debunker_cost": 0.000342, "judge_cost": 0.002626, "total_cost": 0.003535}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003535, "profit_usd": 0.046465, "profit_margin_pct": 92.93}, "metadata": {"search_count": 5, "execution_time_sec": 14.58}}
{"timestamp": "2025-12-30T21:00:42.020302", "claim": "Will artificial intelligence cause mass unemployment by 2030?", "verdict": "Uncertain", "confidence_score": 0.55, "tokens": {"total_input": 3162, "total_output": 480, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 870, "output": 121}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 878, "output": 107}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1414, "output": 252}}, "costs": {"prover_cost": 0.000609, "debunker_cost": 0.000355, "judge_cost": 0.002674, "total_cost": 0.003638}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003638, "profit_usd": 0.046362, "profit_margin_pct": 92.72}, "metadata": {"search_count": 5, "execution_time_sec": 12.37}}
{"timestamp": "2025-12-30T21:01:39.462926", "claim": "Is water wet?", "verdict": "Inconclusive", "confidence_score": 0.65, "tokens": {"total_input": 2848, "total_output": 458, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 773, "output": 110}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 798, "output": 98}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1277, "output": 250}}, "costs": {"prover_cost": 0.000543, "debunker_cost": 0.000323, "judge_cost": 0.002527, "total_cost": 0.003393}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003393, "profit_usd": 0.046607, "profit_margin_pct": 93.21}, "metadata": {"search_count": 5, "execution_time_sec": 11.99}}
{"timestamp": "2025-12-30T21:02:33.531796", "claim": "Does intermittent fasting lead to better weight loss than calorie restriction?", "verdict": "Inconclusive", "confidence_score": 0.65, "tokens": {"total_input": 2973, "total_output": 479, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 775, "output": 117}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 800, "output": 130}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1398, "output": 232}}, "costs": {"prover_cost": 0.00055, "debunker_cost": 0.000359, "judge_cost": 0.002558, "total_cost": 0.003467}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003467, "profit_usd": 0.046533, "profit_margin_pct": 93.07}, "metadata": {"search_count": 5, "execution_time_sec": 13.42}}
{"timestamp": "2025-12-30T21:03:30.471708", "claim": "Does intermittent fasting lead to better weight loss than calorie restriction?", "verdict": "Inconclusive", "confidence_score": 0.65, "tokens": {"total_input": 2962, "total_output": 443, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 775, "output": 117}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 800, "output": 116}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1387, "output": 210}}, "costs": {"prover_cost": 0.00055, "debunker_cost": 0.000344, "judge_cost": 0.002437, "total_cost": 0.00333}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.00333, "profit_usd": 0.04667, "profit_margin_pct": 93.34}, "metadata": {"search_count": 5, "execution_time_sec": 13.09}}
{"timestamp": "2025-12-30T21:04:03.638331", "claim": "Is water wet?", "verdict": "Inconclusive", "confidence_score": 0.6, "tokens": {"total_input": 3197, "total_output": 403, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 870, "output": 113}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 912, "output": 84}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1415, "output": 206}}, "costs": {"prover_cost": 0.000603, "debunker_cost": 0.000339, "judge_cost": 0.002445, "total_cost": 0.003386}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003386, "profit_usd": 0.046614, "profit_margin_pct": 93.23}, "metadata": {"search_count": 5, "execution_time_sec": 11.01}}
{"timestamp": "2025-12-30T21:27:43.693741", "claim": "Does 'ghosting' someone make you a bad person?", "verdict": "Inconclusive", "confidence_score": 0.65, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 2977, "total_output": 469, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 806, "output": 128}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 850, "output": 104}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1321, "output": 237}}, "costs": {"prover_cost": 0.000577, "debunker_cost": 0.000344, "judge_cost": 0.002506, "total_cost": 0.003427}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003427, "profit_usd": 0.046573, "profit_margin_pct": 93.15, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 12.03}}
{"timestamp": "2025-12-30T21:27:43.854207", "claim": "Is water wet?", "verdict": "Inconclusive", "confidence_score": 0.65, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3062, "total_output": 482, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 806, "output": 128}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 850, "output": 104}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1406, "output": 250}}, "costs": {"prover_cost": 0.000577, "debunker_cost": 0.000344, "judge_cost": 0.002656, "total_cost": 0.003577}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003577, "profit_usd": 0.046423, "profit_margin_pct": 92.85, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 12.19}}
{"timestamp": "2025-12-30T21:27:44.019268", "claim": "Is 'rizz' actually a real word or just internet slang?", "verdict": "Inconclusive", "confidence_score": 0.45, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3018, "total_output": 451, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 806, "output": 128}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 850, "output": 104}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1362, "output": 219}}, "costs": {"prover_cost": 0.000577, "debunker_cost": 0.000344, "judge_cost": 0.002457, "total_cost": 0.003378}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003378, "profit_usd": 0.046622, "profit_margin_pct": 93.24, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 12.36}}
{"timestamp": "2025-12-30T21:27:44.151405", "claim": "Will quantum computers break Bitcoin's encryption within 5 years?", "verdict": "Uncertain", "confidence_score": 0.55, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3123, "total_output": 471, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 806, "output": 128}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 850, "output": 104}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1467, "output": 239}}, "costs": {"prover_cost": 0.000577, "debunker_cost": 0.000344, "judge_cost": 0.002662, "total_cost": 0.003583}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003583, "profit_usd": 0.046417, "profit_margin_pct": 92.83, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 12.49}}
{"timestamp": "2025-12-30T21:27:45.099341", "claim": "Are all politicians corrupt?", "verdict": "Unverified", "confidence_score": 0.65, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3009, "total_output": 507, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 806, "output": 128}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 850, "output": 104}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1353, "output": 275}}, "costs": {"prover_cost": 0.000577, "debunker_cost": 0.000344, "judge_cost": 0.002728, "total_cost": 0.003649}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003649, "profit_usd": 0.046351, "profit_margin_pct": 92.7, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 13.44}}
{"timestamp": "2025-12-30T21:27:56.284660", "claim": "Is 'cap' the same as 'no cap' or are they opposites?", "verdict": "Verified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3217, "total_output": 529, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 899, "output": 167}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 884, "output": 132}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1434, "output": 230}}, "costs": {"prover_cost": 0.000662, "debunker_cost": 0.000384, "judge_cost": 0.002584, "total_cost": 0.00363}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.00363, "profit_usd": 0.04637, "profit_margin_pct": 92.74, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 10.68}}
{"timestamp": "2025-12-30T21:27:56.316524", "claim": "Is a hot dog a sandwich?", "verdict": "Inconclusive", "confidence_score": 0.6, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3249, "total_output": 576, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 899, "output": 167}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 884, "output": 132}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1466, "output": 277}}, "costs": {"prover_cost": 0.000662, "debunker_cost": 0.000384, "judge_cost": 0.002851, "total_cost": 0.003897}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003897, "profit_usd": 0.046103, "profit_margin_pct": 92.21, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 10.71}}
{"timestamp": "2025-12-30T21:27:57.402650", "claim": "Does pineapple belong on pizza?", "verdict": "Inconclusive", "confidence_score": 0.65, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3149, "total_output": 565, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 899, "output": 167}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 884, "output": 132}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1366, "output": 266}}, "costs": {"prover_cost": 0.000662, "debunker_cost": 0.000384, "judge_cost": 0.002696, "total_cost": 0.003742}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003742, "profit_usd": 0.046258, "profit_margin_pct": 92.52, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 11.8}}
{"timestamp": "2025-12-30T21:27:57.783774", "claim": "Is capitalism inherently evil?", "verdict": "Inconclusive", "confidence_score": 0.45, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3102, "total_output": 550, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 899, "output": 167}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 884, "output": 132}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1319, "output": 251}}, "costs": {"prover_cost": 0.000662, "debunker_cost": 0.000384, "judge_cost": 0.002574, "total_cost": 0.00362}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.00362, "profit_usd": 0.04638, "profit_margin_pct": 92.76, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 12.18}}
{"timestamp": "2025-12-30T21:27:59.013670", "claim": "Is P = NP likely to be proven true?", "verdict": "Unlikely", "confidence_score": 0.82, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3316, "total_output": 566, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 899, "output": 167}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 884, "output": 132}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1533, "output": 267}}, "costs": {"prover_cost": 0.000662, "debunker_cost": 0.000384, "judge_cost": 0.002868, "total_cost": 0.003914}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003914, "profit_usd": 0.046086, "profit_margin_pct": 92.17, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 13.41}}
{"timestamp": "2025-12-30T21:28:10.543806", "claim": "Does religion cause more harm than good?", "verdict": "Inconclusive", "confidence_score": 0.62, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 2883, "total_output": 504, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 773, "output": 137}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 792, "output": 122}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1318, "output": 245}}, "costs": {"prover_cost": 0.000564, "debunker_cost": 0.000348, "judge_cost": 0.002543, "total_cost": 0.003455}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003455, "profit_usd": 0.046545, "profit_margin_pct": 93.09, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 11.03}}
{"timestamp": "2025-12-30T21:28:10.568935", "claim": "Will Gen Z actually 'cancel' millennials for using skinny jeans?", "verdict": "Uncertain", "confidence_score": 0.45, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 2842, "total_output": 476, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 773, "output": 137}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 792, "output": 122}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1277, "output": 217}}, "costs": {"prover_cost": 0.000564, "debunker_cost": 0.000348, "judge_cost": 0.002362, "total_cost": 0.003274}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003274, "profit_usd": 0.046726, "profit_margin_pct": 93.45, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 11.05}}
{"timestamp": "2025-12-30T21:28:10.838121", "claim": "Does money buy happiness?", "verdict": "Inconclusive", "confidence_score": 0.65, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 2787, "total_output": 546, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 773, "output": 137}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 792, "output": 122}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1222, "output": 287}}, "costs": {"prover_cost": 0.000564, "debunker_cost": 0.000348, "judge_cost": 0.002657, "total_cost": 0.003569}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003569, "profit_usd": 0.046431, "profit_margin_pct": 92.86, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 11.32}}
{"timestamp": "2025-12-30T21:28:10.847636", "claim": "Does quantum entanglement enable faster-than-light communication?", "verdict": "Unverified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 2912, "total_output": 532, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 773, "output": 137}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 792, "output": 122}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1347, "output": 273}}, "costs": {"prover_cost": 0.000564, "debunker_cost": 0.000348, "judge_cost": 0.002712, "total_cost": 0.003624}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003624, "profit_usd": 0.046376, "profit_margin_pct": 92.75, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 11.33}}
{"timestamp": "2025-12-30T21:28:11.790152", "claim": "Is all mainstream media propaganda?", "verdict": "Inconclusive", "confidence_score": 0.65, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 2899, "total_output": 514, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 773, "output": 137}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 792, "output": 122}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1334, "output": 255}}, "costs": {"prover_cost": 0.000564, "debunker_cost": 0.000348, "judge_cost": 0.002609, "total_cost": 0.003521}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003521, "profit_usd": 0.046479, "profit_margin_pct": 92.96, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 12.27}}
{"timestamp": "2025-12-30T21:28:23.569600", "claim": "Will AGI be achieved before 2030?", "verdict": "Uncertain", "confidence_score": 0.45, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 2887, "total_output": 490, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 752, "output": 118}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 701, "output": 169}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1434, "output": 203}}, "costs": {"prover_cost": 0.000537, "debunker_cost": 0.000375, "judge_cost": 0.002449, "total_cost": 0.003361}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003361, "profit_usd": 0.046639, "profit_margin_pct": 93.28, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 11.27}}
{"timestamp": "2025-12-30T21:28:23.885521", "claim": "Is Rust memory-safe without garbage collection?", "verdict": "Verified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 2728, "total_output": 556, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 752, "output": 118}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 701, "output": 169}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1275, "output": 269}}, "costs": {"prover_cost": 0.000537, "debunker_cost": 0.000375, "judge_cost": 0.00262, "total_cost": 0.003532}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003532, "profit_usd": 0.046468, "profit_margin_pct": 92.94, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 11.59}}
{"timestamp": "2025-12-30T21:28:24.248354", "claim": "Are vaccines more dangerous than the diseases they prevent?", "verdict": "Verified", "confidence_score": 0.95, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 2706, "total_output": 486, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 752, "output": 118}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 701, "output": 169}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1253, "output": 199}}, "costs": {"prover_cost": 0.000537, "debunker_cost": 0.000375, "judge_cost": 0.002248, "total_cost": 0.00316}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.00316, "profit_usd": 0.04684, "profit_margin_pct": 93.68, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 11.95}}
{"timestamp": "2025-12-30T21:28:24.663202", "claim": "Is 'bussin' a valid replacement for 'delicious'?", "verdict": "Verified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 2810, "total_output": 525, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 752, "output": 118}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 701, "output": 169}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1357, "output": 238}}, "costs": {"prover_cost": 0.000537, "debunker_cost": 0.000375, "judge_cost": 0.002547, "total_cost": 0.003459}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003459, "profit_usd": 0.046541, "profit_margin_pct": 93.08, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 12.37}}
{"timestamp": "2025-12-30T21:28:24.771809", "claim": "Is artificial intelligence truly intelligent?", "verdict": "Inconclusive", "confidence_score": 0.62, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 2638, "total_output": 521, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 752, "output": 118}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 701, "output": 169}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1185, "output": 234}}, "costs": {"prover_cost": 0.000537, "debunker_cost": 0.000375, "judge_cost": 0.002355, "total_cost": 0.003267}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003267, "profit_usd": 0.046733, "profit_margin_pct": 93.47, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 12.48}}
{"timestamp": "2025-12-30T21:32:16.978274", "claim": "Is capitalism inherently evil?", "verdict": "Inconclusive", "confidence_score": 0.35, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 3433, "total_output": 403, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 881, "output": 102}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 907, "output": 104}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1645, "output": 197}}, "costs": {"prover_cost": 0.0006, "debunker_cost": 0.000359, "judge_cost": 0.00263, "total_cost": 0.00359}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.00359, "profit_usd": -0.00359, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 11.91}}
{"timestamp": "2025-12-30T21:42:32.125863", "claim": "Is capitalism inherently evil?", "verdict": "Inconclusive", "confidence_score": 0.3, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 0, "total_output": 0, "prover": {"input": 0, "output": 0, "model": "N/A"}, "debunker": {"input": 0, "output": 0, "model": "N/A"}, "judge": {"input": 0, "output": 0, "model": "N/A"}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.0, "total_cost": 0.0}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.0, "profit_usd": 0.0, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 0, "execution_time_sec": 0.0}}
{"timestamp": "2025-12-30T21:42:44.120142", "claim": "Are all politicians corrupt?", "verdict": "Unverified", "confidence_score": 0.65, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3213, "total_output": 502, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 806, "output": 123}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 850, "output": 112}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1557, "output": 267}}, "costs": {"prover_cost": 0.000573, "debunker_cost": 0.000353, "judge_cost": 0.002892, "total_cost": 0.003817}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003817, "profit_usd": 0.046183, "profit_margin_pct": 92.37, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 11.99}}
{"timestamp": "2025-12-30T21:42:56.451584", "claim": "Does water freeze at 0\u00b0C?", "verdict": "Verified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3176, "total_output": 479, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 784, "output": 107}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 810, "output": 110}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1582, "output": 262}}, "costs": {"prover_cost": 0.000547, "debunker_cost": 0.00034, "judge_cost": 0.002892, "total_cost": 0.003779}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003779, "profit_usd": 0.046221, "profit_margin_pct": 92.44, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 12.33}}
{"timestamp": "2025-12-30T21:53:36.583080", "claim": "Is 'rizz' actually a real word or just internet slang?", "verdict": "Unverified", "confidence_score": 0.55, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3079, "total_output": 519, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 751, "output": 148}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 788, "output": 86}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1540, "output": 285}}, "costs": {"prover_cost": 0.00056, "debunker_cost": 0.000307, "judge_cost": 0.002965, "total_cost": 0.003832}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003832, "profit_usd": 0.046168, "profit_margin_pct": 92.34, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 15.09}}
{"timestamp": "2025-12-30T21:53:36.788324", "claim": "Does pineapple belong on pizza?", "verdict": "Inconclusive", "confidence_score": 0.3, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 0, "total_output": 0, "prover": {"input": 0, "output": 0, "model": "N/A"}, "debunker": {"input": 0, "output": 0, "model": "N/A"}, "judge": {"input": 0, "output": 0, "model": "N/A"}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.0, "total_cost": 0.0}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.0, "profit_usd": 0.0, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 0, "execution_time_sec": 0.0}}
{"timestamp": "2025-12-30T21:53:36.993227", "claim": "Does religion cause more harm than good?", "verdict": "Inconclusive", "confidence_score": 0.3, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 0, "total_output": 0, "prover": {"input": 0, "output": 0, "model": "N/A"}, "debunker": {"input": 0, "output": 0, "model": "N/A"}, "judge": {"input": 0, "output": 0, "model": "N/A"}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.0, "total_cost": 0.0}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.0, "profit_usd": 0.0, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 0, "execution_time_sec": 0.0}}
{"timestamp": "2025-12-30T21:53:46.927792", "claim": "Will AGI be achieved before 2030?", "verdict": "Uncertain", "confidence_score": 0.42, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3277, "total_output": 446, "prover": {"model": "gemini-2.0-flash-exp", "input": 953, "output": 74}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 949, "output": 119}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1375, "output": 253}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.00264, "total_cost": 0.00264}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.00264, "profit_usd": 0.04736, "profit_margin_pct": 94.72, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 9.73}}
{"timestamp": "2025-12-30T21:54:04.489715", "claim": "Is 'bussin' a valid replacement for 'delicious'?", "verdict": "Unverified", "confidence_score": 0.65, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3099, "total_output": 503, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 752, "output": 137}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 784, "output": 112}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1563, "output": 254}}, "costs": {"prover_cost": 0.000552, "debunker_cost": 0.000335, "judge_cost": 0.002833, "total_cost": 0.00372}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.00372, "profit_usd": 0.04628, "profit_margin_pct": 92.56, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 17.36}}
{"timestamp": "2025-12-30T21:54:14.576003", "claim": "Does free will exist?", "verdict": "Uncertain", "confidence_score": 0.55, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 2727, "total_output": 418, "prover": {"model": "gemini-2.0-flash-exp", "input": 764, "output": 90}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 760, "output": 95}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1203, "output": 233}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002368, "total_cost": 0.002368}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002368, "profit_usd": 0.047632, "profit_margin_pct": 95.26, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 9.88}}
{"timestamp": "2025-12-30T21:54:29.258396", "claim": "Does the government control the weather?", "verdict": "Unverified", "confidence_score": 0.75, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3091, "total_output": 494, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 770, "output": 154}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 795, "output": 104}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1526, "output": 236}}, "costs": {"prover_cost": 0.000576, "debunker_cost": 0.000329, "judge_cost": 0.002706, "total_cost": 0.003611}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003611, "profit_usd": 0.046389, "profit_margin_pct": 92.78, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 14.48}}
{"timestamp": "2025-12-30T21:54:39.408198", "claim": "Is cold fusion scientifically achievable?", "verdict": "Inconclusive", "confidence_score": 0.35, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 3600, "total_output": 468, "prover": {"model": "gemini-2.0-flash-exp", "input": 977, "output": 82}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 998, "output": 126}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1625, "output": 260}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002925, "total_cost": 0.002925}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.002925, "profit_usd": -0.002925, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 9.95}}
{"timestamp": "2025-12-30T21:54:52.536078", "claim": "Is calling someone a 'CEO' actually a compliment?", "verdict": "Unverified", "confidence_score": 0.75, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3002, "total_output": 527, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 730, "output": 103}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 796, "output": 101}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1476, "output": 323}}, "costs": {"prover_cost": 0.000512, "debunker_cost": 0.000326, "judge_cost": 0.003091, "total_cost": 0.003929}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003929, "profit_usd": 0.046071, "profit_margin_pct": 92.14, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 12.92}}
{"timestamp": "2025-12-30T21:55:02.567724", "claim": "Does art need to have meaning?", "verdict": "Verified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3068, "total_output": 443, "prover": {"model": "gemini-2.0-flash-exp", "input": 798, "output": 119}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 819, "output": 75}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1451, "output": 249}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002696, "total_cost": 0.002696}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002696, "profit_usd": 0.047304, "profit_margin_pct": 94.61, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 9.83}}
{"timestamp": "2025-12-30T21:55:14.840556", "claim": "Are all politicians corrupt?", "verdict": "Unverified", "confidence_score": 0.65, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3203, "total_output": 473, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 806, "output": 109}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 850, "output": 109}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1547, "output": 255}}, "costs": {"prover_cost": 0.000562, "debunker_cost": 0.000349, "judge_cost": 0.002822, "total_cost": 0.003733}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003733, "profit_usd": 0.046267, "profit_margin_pct": 92.53, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 12.07}}
{"timestamp": "2025-12-30T21:55:25.530171", "claim": "Is P = NP likely to be proven true?", "verdict": "Unlikely", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3180, "total_output": 456, "prover": {"model": "gemini-2.0-flash-exp", "input": 921, "output": 77}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 917, "output": 102}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1342, "output": 277}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002727, "total_cost": 0.002727}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002727, "profit_usd": 0.047273, "profit_margin_pct": 94.55, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 10.49}}
{"timestamp": "2025-12-30T21:55:37.221744", "claim": "Is 'cap' the same as 'no cap' or are they opposites?", "verdict": "Verified", "confidence_score": 0.95, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3288, "total_output": 481, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 826, "output": 115}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 859, "output": 122}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1603, "output": 244}}, "costs": {"prover_cost": 0.000578, "debunker_cost": 0.000366, "judge_cost": 0.002823, "total_cost": 0.003767}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003767, "profit_usd": 0.046233, "profit_margin_pct": 92.47, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 11.49}}
{"timestamp": "2025-12-30T21:55:48.480524", "claim": "Does money buy happiness?", "verdict": "Verified", "confidence_score": 0.75, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3036, "total_output": 491, "prover": {"model": "gemini-2.0-flash-exp", "input": 800, "output": 76}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 821, "output": 93}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1415, "output": 322}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.003025, "total_cost": 0.003025}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003025, "profit_usd": 0.046975, "profit_margin_pct": 93.95, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 11.06}}
{"timestamp": "2025-12-30T21:56:01.472901", "claim": "Are vaccines more dangerous than the diseases they prevent?", "verdict": "Unverified", "confidence_score": 0.95, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 2826, "total_output": 564, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 678, "output": 142}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 701, "output": 132}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1447, "output": 290}}, "costs": {"prover_cost": 0.000512, "debunker_cost": 0.000334, "judge_cost": 0.002897, "total_cost": 0.003744}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003744, "profit_usd": 0.046256, "profit_margin_pct": 92.51, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 12.79}}
{"timestamp": "2025-12-30T21:56:12.275868", "claim": "Does SHA-256 have known collision vulnerabilities?", "verdict": "Verified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3653, "total_output": 452, "prover": {"model": "gemini-2.0-flash-exp", "input": 1009, "output": 75}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 1030, "output": 126}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1614, "output": 251}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002869, "total_cost": 0.002869}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002869, "profit_usd": 0.047131, "profit_margin_pct": 94.26, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 10.6}}
{"timestamp": "2025-12-30T21:56:27.321500", "claim": "Is 'slay' still cool or is it cringe now?", "verdict": "Inconclusive", "confidence_score": 0.45, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3444, "total_output": 541, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 871, "output": 108}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 919, "output": 122}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1654, "output": 311}}, "costs": {"prover_cost": 0.000599, "debunker_cost": 0.000382, "judge_cost": 0.003209, "total_cost": 0.004191}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.004191, "profit_usd": 0.045809, "profit_margin_pct": 91.62, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 14.84}}
{"timestamp": "2025-12-30T21:56:37.461676", "claim": "Does light have mass?", "verdict": "Unverified", "confidence_score": 0.75, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3067, "total_output": 472, "prover": {"model": "gemini-2.0-flash-exp", "input": 795, "output": 86}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 816, "output": 79}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1456, "output": 307}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002991, "total_cost": 0.002991}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002991, "profit_usd": 0.047009, "profit_margin_pct": 94.02, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 9.94}}
{"timestamp": "2025-12-30T21:56:37.665927", "claim": "Is democracy a failed system?", "verdict": "Inconclusive", "confidence_score": 0.3, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 0, "total_output": 0, "prover": {"input": 0, "output": 0, "model": "N/A"}, "debunker": {"input": 0, "output": 0, "model": "N/A"}, "judge": {"input": 0, "output": 0, "model": "N/A"}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.0, "total_cost": 0.0}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.0, "profit_usd": 0.0, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 0, "execution_time_sec": 0.0}}
{"timestamp": "2025-12-30T21:56:49.677632", "claim": "Will CRISPR eliminate genetic diseases by 2035?", "verdict": "Uncertain", "confidence_score": 0.45, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3054, "total_output": 526, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 830, "output": 135}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 793, "output": 124}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1431, "output": 267}}, "costs": {"prover_cost": 0.000596, "debunker_cost": 0.000351, "judge_cost": 0.002766, "total_cost": 0.003713}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003713, "profit_usd": 0.046287, "profit_margin_pct": 92.57, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 11.81}}
{"timestamp": "2025-12-30T21:57:00.068142", "claim": "Is 'rizz' actually a real word or just internet slang?", "verdict": "Verified", "confidence_score": 0.92, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3148, "total_output": 451, "prover": {"model": "gemini-2.0-flash-exp", "input": 823, "output": 77}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 844, "output": 92}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1481, "output": 282}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002891, "total_cost": 0.002891}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002891, "profit_usd": 0.047109, "profit_margin_pct": 94.22, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 10.19}}
{"timestamp": "2025-12-30T21:57:00.272754", "claim": "Does pineapple belong on pizza?", "verdict": "Inconclusive", "confidence_score": 0.3, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 0, "total_output": 0, "prover": {"input": 0, "output": 0, "model": "N/A"}, "debunker": {"input": 0, "output": 0, "model": "N/A"}, "judge": {"input": 0, "output": 0, "model": "N/A"}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.0, "total_cost": 0.0}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.0, "profit_usd": 0.0, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 0, "execution_time_sec": 0.0}}
{"timestamp": "2025-12-30T21:57:00.478901", "claim": "Does religion cause more harm than good?", "verdict": "Inconclusive", "confidence_score": 0.3, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 0, "total_output": 0, "prover": {"input": 0, "output": 0, "model": "N/A"}, "debunker": {"input": 0, "output": 0, "model": "N/A"}, "judge": {"input": 0, "output": 0, "model": "N/A"}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.0, "total_cost": 0.0}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.0, "profit_usd": 0.0, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 0, "execution_time_sec": 0.0}}
{"timestamp": "2025-12-30T21:57:11.992599", "claim": "Will AGI be achieved before 2030?", "verdict": "Uncertain", "confidence_score": 0.45, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3177, "total_output": 461, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 866, "output": 133}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 867, "output": 114}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1444, "output": 214}}, "costs": {"prover_cost": 0.000616, "debunker_cost": 0.000359, "judge_cost": 0.002514, "total_cost": 0.003489}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003489, "profit_usd": 0.046511, "profit_margin_pct": 93.02, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 11.31}}
{"timestamp": "2025-12-30T21:57:22.055255", "claim": "Is 'bussin' a valid replacement for 'delicious'?", "verdict": "Verified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3195, "total_output": 411, "prover": {"model": "gemini-2.0-flash-exp", "input": 853, "output": 74}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 874, "output": 76}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1468, "output": 261}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002773, "total_cost": 0.002773}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002773, "profit_usd": 0.047227, "profit_margin_pct": 94.45, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 9.86}}
{"timestamp": "2025-12-30T21:57:33.614743", "claim": "Does free will exist?", "verdict": "Uncertain", "confidence_score": 0.45, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 2700, "total_output": 428, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 733, "output": 124}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 731, "output": 94}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1236, "output": 210}}, "costs": {"prover_cost": 0.00053, "debunker_cost": 0.000301, "judge_cost": 0.002286, "total_cost": 0.003117}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003117, "profit_usd": 0.046883, "profit_margin_pct": 93.77, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 11.35}}
{"timestamp": "2025-12-30T21:57:44.242999", "claim": "Does the government control the weather?", "verdict": "Unverified", "confidence_score": 0.92, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3166, "total_output": 481, "prover": {"model": "gemini-2.0-flash-exp", "input": 834, "output": 74}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 855, "output": 91}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1477, "output": 316}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.003057, "total_cost": 0.003057}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003057, "profit_usd": 0.046943, "profit_margin_pct": 93.89, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 10.42}}
{"timestamp": "2025-12-30T21:57:58.150238", "claim": "Is cold fusion scientifically achievable?", "verdict": "Unverified", "confidence_score": 0.45, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 2818, "total_output": 502, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 682, "output": 115}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 697, "output": 124}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1439, "output": 263}}, "costs": {"prover_cost": 0.000493, "debunker_cost": 0.000325, "judge_cost": 0.002754, "total_cost": 0.003572}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003572, "profit_usd": 0.046428, "profit_margin_pct": 92.86, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 13.7}}
{"timestamp": "2025-12-30T21:58:08.772531", "claim": "Is calling someone a 'CEO' actually a compliment?", "verdict": "Inconclusive", "confidence_score": 0.15, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 2956, "total_output": 459, "prover": {"model": "gemini-2.0-flash-exp", "input": 769, "output": 85}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 790, "output": 83}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1397, "output": 291}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002852, "total_cost": 0.002852}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.002852, "profit_usd": -0.002852, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 10.42}}
{"timestamp": "2025-12-30T21:58:20.842516", "claim": "Does art need to have meaning?", "verdict": "Inconclusive", "confidence_score": 0.4, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3079, "total_output": 498, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 774, "output": 97}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 793, "output": 116}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1512, "output": 285}}, "costs": {"prover_cost": 0.000533, "debunker_cost": 0.000342, "judge_cost": 0.002937, "total_cost": 0.003812}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003812, "profit_usd": 0.046188, "profit_margin_pct": 92.38, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 11.87}}
{"timestamp": "2025-12-30T21:58:30.451215", "claim": "Are all politicians corrupt?", "verdict": "Unverified", "confidence_score": 0.72, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3375, "total_output": 472, "prover": {"model": "gemini-2.0-flash-exp", "input": 911, "output": 117}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 932, "output": 90}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1532, "output": 265}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002857, "total_cost": 0.002857}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002857, "profit_usd": 0.047143, "profit_margin_pct": 94.29, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 9.4}}
{"timestamp": "2025-12-30T21:58:47.095638", "claim": "Is P = NP likely to be proven true?", "verdict": "Unlikely", "confidence_score": 0.82, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3252, "total_output": 539, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 866, "output": 119}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 869, "output": 145}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1517, "output": 275}}, "costs": {"prover_cost": 0.000605, "debunker_cost": 0.000394, "judge_cost": 0.002892, "total_cost": 0.003891}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003891, "profit_usd": 0.046109, "profit_margin_pct": 92.22, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 16.44}}
{"timestamp": "2025-12-30T21:58:57.214797", "claim": "Is 'cap' the same as 'no cap' or are they opposites?", "verdict": "Verified", "confidence_score": 0.9, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3182, "total_output": 478, "prover": {"model": "gemini-2.0-flash-exp", "input": 840, "output": 73}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 861, "output": 91}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1481, "output": 314}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.003051, "total_cost": 0.003051}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003051, "profit_usd": 0.046949, "profit_margin_pct": 93.9, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 9.91}}
{"timestamp": "2025-12-30T21:59:10.883505", "claim": "Does money buy happiness?", "verdict": "Verified", "confidence_score": 0.75, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 2919, "total_output": 504, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 723, "output": 114}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 746, "output": 114}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1450, "output": 276}}, "costs": {"prover_cost": 0.000517, "debunker_cost": 0.000327, "judge_cost": 0.00283, "total_cost": 0.003673}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003673, "profit_usd": 0.046327, "profit_margin_pct": 92.65, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 13.47}}
{"timestamp": "2025-12-30T21:59:21.382589", "claim": "Are vaccines more dangerous than the diseases they prevent?", "verdict": "Verified", "confidence_score": 0.95, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 2792, "total_output": 500, "prover": {"model": "gemini-2.0-flash-exp", "input": 701, "output": 80}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 722, "output": 122}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1369, "output": 298}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002859, "total_cost": 0.002859}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002859, "profit_usd": 0.047141, "profit_margin_pct": 94.28, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 10.29}}
{"timestamp": "2025-12-30T21:59:41.123389", "claim": "Does SHA-256 have known collision vulnerabilities?", "verdict": "Unverified", "confidence_score": 0.65, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3183, "total_output": 568, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 773, "output": 140}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 805, "output": 109}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1605, "output": 319}}, "costs": {"prover_cost": 0.000567, "debunker_cost": 0.000337, "judge_cost": 0.0032, "total_cost": 0.004104}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.004104, "profit_usd": 0.045896, "profit_margin_pct": 91.79, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 19.54}}
{"timestamp": "2025-12-30T21:59:51.747469", "claim": "Is 'slay' still cool or is it cringe now?", "verdict": "Verified", "confidence_score": 0.75, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3311, "total_output": 425, "prover": {"model": "gemini-2.0-flash-exp", "input": 879, "output": 77}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 900, "output": 95}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1532, "output": 253}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002797, "total_cost": 0.002797}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002797, "profit_usd": 0.047203, "profit_margin_pct": 94.41, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 10.42}}
{"timestamp": "2025-12-30T22:00:02.903421", "claim": "Does light have mass?", "verdict": "Unverified", "confidence_score": 0.75, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 2965, "total_output": 499, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 727, "output": 112}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 752, "output": 100}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1486, "output": 287}}, "costs": {"prover_cost": 0.000517, "debunker_cost": 0.000313, "judge_cost": 0.002921, "total_cost": 0.003751}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003751, "profit_usd": 0.046249, "profit_margin_pct": 92.5, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 10.95}}
{"timestamp": "2025-12-30T22:00:03.108166", "claim": "Is democracy a failed system?", "verdict": "Inconclusive", "confidence_score": 0.3, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 0, "total_output": 0, "prover": {"input": 0, "output": 0, "model": "N/A"}, "debunker": {"input": 0, "output": 0, "model": "N/A"}, "judge": {"input": 0, "output": 0, "model": "N/A"}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.0, "total_cost": 0.0}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.0, "profit_usd": 0.0, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 0, "execution_time_sec": 0.0}}
{"timestamp": "2025-12-30T22:00:14.256862", "claim": "Will CRISPR eliminate genetic diseases by 2035?", "verdict": "Uncertain", "confidence_score": 0.45, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3073, "total_output": 502, "prover": {"model": "gemini-2.0-flash-exp", "input": 871, "output": 100}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 867, "output": 97}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1335, "output": 305}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.00286, "total_cost": 0.00286}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.00286, "profit_usd": 0.04714, "profit_margin_pct": 94.28, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 10.94}}
{"timestamp": "2025-12-30T22:00:25.720884", "claim": "Is 'rizz' actually a real word or just internet slang?", "verdict": "Verified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3543, "total_output": 471, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 898, "output": 119}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 926, "output": 115}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1719, "output": 237}}, "costs": {"prover_cost": 0.000624, "debunker_cost": 0.000377, "judge_cost": 0.002904, "total_cost": 0.003904}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003904, "profit_usd": 0.046096, "profit_margin_pct": 92.19, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 11.26}}
{"timestamp": "2025-12-30T22:00:25.927234", "claim": "Does pineapple belong on pizza?", "verdict": "Inconclusive", "confidence_score": 0.3, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 0, "total_output": 0, "prover": {"input": 0, "output": 0, "model": "N/A"}, "debunker": {"input": 0, "output": 0, "model": "N/A"}, "judge": {"input": 0, "output": 0, "model": "N/A"}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.0, "total_cost": 0.0}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.0, "profit_usd": 0.0, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 0, "execution_time_sec": 0.0}}
{"timestamp": "2025-12-30T22:00:26.132802", "claim": "Does religion cause more harm than good?", "verdict": "Inconclusive", "confidence_score": 0.3, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 0, "total_output": 0, "prover": {"input": 0, "output": 0, "model": "N/A"}, "debunker": {"input": 0, "output": 0, "model": "N/A"}, "judge": {"input": 0, "output": 0, "model": "N/A"}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.0, "total_cost": 0.0}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.0, "profit_usd": 0.0, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 0, "execution_time_sec": 0.0}}
{"timestamp": "2025-12-30T22:00:36.601643", "claim": "Will AGI be achieved before 2030?", "verdict": "Uncertain", "confidence_score": 0.45, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3568, "total_output": 479, "prover": {"model": "gemini-2.0-flash-exp", "input": 1045, "output": 78}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 1041, "output": 139}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1482, "output": 262}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002792, "total_cost": 0.002792}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002792, "profit_usd": 0.047208, "profit_margin_pct": 94.42, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 10.27}}
{"timestamp": "2025-12-30T22:00:50.375383", "claim": "Is 'bussin' a valid replacement for 'delicious'?", "verdict": "Verified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3098, "total_output": 510, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 752, "output": 126}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 784, "output": 126}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1562, "output": 258}}, "costs": {"prover_cost": 0.000543, "debunker_cost": 0.00035, "judge_cost": 0.002852, "total_cost": 0.003745}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003745, "profit_usd": 0.046255, "profit_margin_pct": 92.51, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 13.57}}
{"timestamp": "2025-12-30T22:01:00.889082", "claim": "Does free will exist?", "verdict": "Uncertain", "confidence_score": 0.55, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 2607, "total_output": 405, "prover": {"model": "gemini-2.0-flash-exp", "input": 741, "output": 65}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 737, "output": 78}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1129, "output": 262}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002439, "total_cost": 0.002439}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002439, "profit_usd": 0.047561, "profit_margin_pct": 95.12, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 10.31}}
{"timestamp": "2025-12-30T22:01:16.702234", "claim": "Does the government control the weather?", "verdict": "Unverified", "confidence_score": 0.92, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3230, "total_output": 523, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 800, "output": 152}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 831, "output": 106}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1599, "output": 265}}, "costs": {"prover_cost": 0.000592, "debunker_cost": 0.000341, "judge_cost": 0.002924, "total_cost": 0.003857}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003857, "profit_usd": 0.046143, "profit_margin_pct": 92.29, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 15.61}}
{"timestamp": "2025-12-30T22:01:27.775293", "claim": "Is cold fusion scientifically achievable?", "verdict": "Inconclusive", "confidence_score": 0.45, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3499, "total_output": 494, "prover": {"model": "gemini-2.0-flash-exp", "input": 955, "output": 112}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 976, "output": 98}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1568, "output": 284}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002988, "total_cost": 0.002988}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002988, "profit_usd": 0.047012, "profit_margin_pct": 94.02, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 10.87}}
{"timestamp": "2025-12-30T22:01:42.202097", "claim": "Is calling someone a 'CEO' actually a compliment?", "verdict": "Unverified", "confidence_score": 0.45, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 2856, "total_output": 541, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 675, "output": 123}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 734, "output": 98}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1447, "output": 320}}, "costs": {"prover_cost": 0.000495, "debunker_cost": 0.000306, "judge_cost": 0.003047, "total_cost": 0.003848}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003848, "profit_usd": 0.046152, "profit_margin_pct": 92.3, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 14.22}}
{"timestamp": "2025-12-30T22:01:53.124794", "claim": "Does art need to have meaning?", "verdict": "Inconclusive", "confidence_score": 0.4, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3485, "total_output": 489, "prover": {"model": "gemini-2.0-flash-exp", "input": 936, "output": 115}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 957, "output": 95}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1592, "output": 279}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002987, "total_cost": 0.002987}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002987, "profit_usd": 0.047013, "profit_margin_pct": 94.03, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 10.72}}
{"timestamp": "2025-12-30T22:02:03.553908", "claim": "Are all politicians corrupt?", "verdict": "Unverified", "confidence_score": 0.65, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3028, "total_output": 488, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 759, "output": 103}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 807, "output": 108}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1462, "output": 277}}, "costs": {"prover_cost": 0.000529, "debunker_cost": 0.000337, "judge_cost": 0.002847, "total_cost": 0.003713}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003713, "profit_usd": 0.046287, "profit_margin_pct": 92.57, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 10.22}}
{"timestamp": "2025-12-30T22:02:12.769883", "claim": "Is P = NP likely to be proven true?", "verdict": "Unlikely", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3262, "total_output": 418, "prover": {"model": "gemini-2.0-flash-exp", "input": 931, "output": 99}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 927, "output": 101}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1404, "output": 218}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002494, "total_cost": 0.002494}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002494, "profit_usd": 0.047506, "profit_margin_pct": 95.01, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 9.01}}
{"timestamp": "2025-12-30T22:02:26.403419", "claim": "Is 'cap' the same as 'no cap' or are they opposites?", "verdict": "Unverified", "confidence_score": 0.65, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3240, "total_output": 536, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 800, "output": 135}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 832, "output": 118}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1608, "output": 283}}, "costs": {"prover_cost": 0.000579, "debunker_cost": 0.000354, "judge_cost": 0.003023, "total_cost": 0.003956}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003956, "profit_usd": 0.046044, "profit_margin_pct": 92.09, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 13.43}}
{"timestamp": "2025-12-30T22:02:36.482530", "claim": "Does money buy happiness?", "verdict": "Verified", "confidence_score": 0.75, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 2996, "total_output": 430, "prover": {"model": "gemini-2.0-flash-exp", "input": 812, "output": 63}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 833, "output": 77}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1351, "output": 290}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002801, "total_cost": 0.002801}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002801, "profit_usd": 0.047199, "profit_margin_pct": 94.4, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 9.87}}
{"timestamp": "2025-12-30T22:02:46.454010", "claim": "Are vaccines more dangerous than the diseases they prevent?", "verdict": "Unverified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 2748, "total_output": 415, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 678, "output": 80}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 701, "output": 121}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1369, "output": 214}}, "costs": {"prover_cost": 0.000463, "debunker_cost": 0.000322, "judge_cost": 0.002439, "total_cost": 0.003225}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003225, "profit_usd": 0.046775, "profit_margin_pct": 93.55, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 9.76}}
{"timestamp": "2025-12-30T22:02:57.892710", "claim": "Does SHA-256 have known collision vulnerabilities?", "verdict": "Verified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3581, "total_output": 496, "prover": {"model": "gemini-2.0-flash-exp", "input": 993, "output": 94}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 1014, "output": 96}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1574, "output": 306}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.003104, "total_cost": 0.003104}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003104, "profit_usd": 0.046896, "profit_margin_pct": 93.79, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 11.23}}
{"timestamp": "2025-12-30T22:03:11.378085", "claim": "Is 'slay' still cool or is it cringe now?", "verdict": "Inconclusive", "confidence_score": 0.45, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3249, "total_output": 507, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 802, "output": 120}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 843, "output": 123}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1604, "output": 264}}, "costs": {"prover_cost": 0.000568, "debunker_cost": 0.000363, "judge_cost": 0.002924, "total_cost": 0.003855}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003855, "profit_usd": 0.046145, "profit_margin_pct": 92.29, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 13.28}}
{"timestamp": "2025-12-30T22:03:20.465960", "claim": "Does light have mass?", "verdict": "Unverified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3066, "total_output": 385, "prover": {"model": "gemini-2.0-flash-exp", "input": 802, "output": 79}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 823, "output": 81}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1441, "output": 225}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002566, "total_cost": 0.002566}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002566, "profit_usd": 0.047434, "profit_margin_pct": 94.87, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 8.88}}
{"timestamp": "2025-12-30T22:03:20.671706", "claim": "Is democracy a failed system?", "verdict": "Inconclusive", "confidence_score": 0.3, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 0, "total_output": 0, "prover": {"input": 0, "output": 0, "model": "N/A"}, "debunker": {"input": 0, "output": 0, "model": "N/A"}, "judge": {"input": 0, "output": 0, "model": "N/A"}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.0, "total_cost": 0.0}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.0, "profit_usd": 0.0, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 0, "execution_time_sec": 0.0}}
{"timestamp": "2025-12-30T22:03:39.999198", "claim": "Will CRISPR eliminate genetic diseases by 2035?", "verdict": "Uncertain", "confidence_score": 0.45, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3264, "total_output": 572, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 863, "output": 184}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 834, "output": 140}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1567, "output": 248}}, "costs": {"prover_cost": 0.000655, "debunker_cost": 0.000379, "judge_cost": 0.002807, "total_cost": 0.003841}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003841, "profit_usd": 0.046159, "profit_margin_pct": 92.32, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 19.12}}
{"timestamp": "2025-12-30T22:03:49.945753", "claim": "Is 'rizz' actually a real word or just internet slang?", "verdict": "Verified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3652, "total_output": 433, "prover": {"model": "gemini-2.0-flash-exp", "input": 993, "output": 81}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 1014, "output": 82}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1645, "output": 270}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002995, "total_cost": 0.002995}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002995, "profit_usd": 0.047005, "profit_margin_pct": 94.01, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 9.74}}
{"timestamp": "2025-12-30T22:03:50.151173", "claim": "Does pineapple belong on pizza?", "verdict": "Inconclusive", "confidence_score": 0.3, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 0, "total_output": 0, "prover": {"input": 0, "output": 0, "model": "N/A"}, "debunker": {"input": 0, "output": 0, "model": "N/A"}, "judge": {"input": 0, "output": 0, "model": "N/A"}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.0, "total_cost": 0.0}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.0, "profit_usd": 0.0, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 0, "execution_time_sec": 0.0}}
{"timestamp": "2025-12-30T22:03:50.356902", "claim": "Does religion cause more harm than good?", "verdict": "Inconclusive", "confidence_score": 0.3, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 0, "total_output": 0, "prover": {"input": 0, "output": 0, "model": "N/A"}, "debunker": {"input": 0, "output": 0, "model": "N/A"}, "judge": {"input": 0, "output": 0, "model": "N/A"}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.0, "total_cost": 0.0}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.0, "profit_usd": 0.0, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 0, "execution_time_sec": 0.0}}
{"timestamp": "2025-12-30T22:04:11.255819", "claim": "Will AGI be achieved before 2030?", "verdict": "Uncertain", "confidence_score": 0.45, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3175, "total_output": 539, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 866, "output": 130}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 867, "output": 107}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1442, "output": 302}}, "costs": {"prover_cost": 0.000614, "debunker_cost": 0.000352, "judge_cost": 0.002952, "total_cost": 0.003917}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003917, "profit_usd": 0.046083, "profit_margin_pct": 92.17, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 20.7}}
{"timestamp": "2025-12-30T22:04:21.860540", "claim": "Is 'bussin' a valid replacement for 'delicious'?", "verdict": "Verified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3234, "total_output": 443, "prover": {"model": "gemini-2.0-flash-exp", "input": 853, "output": 110}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 874, "output": 84}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1507, "output": 249}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002752, "total_cost": 0.002752}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002752, "profit_usd": 0.047248, "profit_margin_pct": 94.5, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 10.4}}
{"timestamp": "2025-12-30T22:04:38.564732", "claim": "Does free will exist?", "verdict": "Uncertain", "confidence_score": 0.55, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 2821, "total_output": 412, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 767, "output": 116}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 765, "output": 121}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1289, "output": 175}}, "costs": {"prover_cost": 0.000544, "debunker_cost": 0.00034, "judge_cost": 0.002164, "total_cost": 0.003048}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003048, "profit_usd": 0.046952, "profit_margin_pct": 93.9, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 16.5}}
{"timestamp": "2025-12-30T22:04:47.422027", "claim": "Does the government control the weather?", "verdict": "Unverified", "confidence_score": 0.65, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3129, "total_output": 384, "prover": {"model": "gemini-2.0-flash-exp", "input": 825, "output": 65}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 846, "output": 86}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1458, "output": 233}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002623, "total_cost": 0.002623}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002623, "profit_usd": 0.047377, "profit_margin_pct": 94.75, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 8.65}}
{"timestamp": "2025-12-30T22:05:02.000547", "claim": "Is cold fusion scientifically achievable?", "verdict": "Unverified", "confidence_score": 0.45, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3313, "total_output": 552, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 837, "output": 119}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 852, "output": 114}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1624, "output": 319}}, "costs": {"prover_cost": 0.000588, "debunker_cost": 0.000355, "judge_cost": 0.003219, "total_cost": 0.004162}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.004162, "profit_usd": 0.045838, "profit_margin_pct": 91.68, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 14.38}}
{"timestamp": "2025-12-30T22:05:12.779295", "claim": "Is calling someone a 'CEO' actually a compliment?", "verdict": "Verified", "confidence_score": 0.75, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 2812, "total_output": 469, "prover": {"model": "gemini-2.0-flash-exp", "input": 726, "output": 65}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 747, "output": 83}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1339, "output": 321}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002944, "total_cost": 0.002944}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002944, "profit_usd": 0.047056, "profit_margin_pct": 94.11, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 10.58}}
{"timestamp": "2025-12-30T22:06:31.608449", "claim": "Is P = NP likely to be proven true?", "verdict": "Unlikely", "confidence_score": 0.75, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3262, "total_output": 490, "prover": {"model": "gemini-2.0-flash-exp", "input": 956, "output": 102}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 876, "output": 107}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1430, "output": 281}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.000354, "judge_cost": 0.002835, "total_cost": 0.003189}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003189, "profit_usd": 0.046811, "profit_margin_pct": 93.62, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 14.99}}
{"timestamp": "2025-12-30T22:06:41.668952", "claim": "Is 'cap' the same as 'no cap' or are they opposites?", "verdict": "Verified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3272, "total_output": 420, "prover": {"model": "gemini-2.0-flash-exp", "input": 868, "output": 81}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 889, "output": 81}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1515, "output": 258}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002805, "total_cost": 0.002805}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002805, "profit_usd": 0.047195, "profit_margin_pct": 94.39, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 9.86}}
{"timestamp": "2025-12-30T22:07:16.075800", "claim": "Does money buy happiness?", "verdict": "Verified", "confidence_score": 0.75, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 2889, "total_output": 516, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 723, "output": 94}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 746, "output": 108}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1420, "output": 314}}, "costs": {"prover_cost": 0.000501, "debunker_cost": 0.00032, "judge_cost": 0.00299, "total_cost": 0.003811}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003811, "profit_usd": 0.046189, "profit_margin_pct": 92.38, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 34.2}}
{"timestamp": "2025-12-30T22:07:26.889847", "claim": "Are vaccines more dangerous than the diseases they prevent?", "verdict": "Verified", "confidence_score": 0.9, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 2971, "total_output": 456, "prover": {"model": "gemini-2.0-flash-exp", "input": 765, "output": 81}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 786, "output": 91}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1420, "output": 284}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.00284, "total_cost": 0.00284}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.00284, "profit_usd": 0.04716, "profit_margin_pct": 94.32, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 10.61}}
{"timestamp": "2025-12-30T22:08:02.454943", "claim": "Does SHA-256 have known collision vulnerabilities?", "verdict": "Unverified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3433, "total_output": 506, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 879, "output": 111}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 910, "output": 112}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1644, "output": 283}}, "costs": {"prover_cost": 0.000606, "debunker_cost": 0.000369, "judge_cost": 0.003059, "total_cost": 0.004034}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.004034, "profit_usd": 0.045966, "profit_margin_pct": 91.93, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 35.36}}
{"timestamp": "2025-12-30T22:08:10.911509", "claim": "Is 'slay' still cool or is it cringe now?", "verdict": "Unverified", "confidence_score": 0.65, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3387, "total_output": 412, "prover": {"model": "gemini-2.0-flash-exp", "input": 899, "output": 107}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 920, "output": 101}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1568, "output": 204}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002588, "total_cost": 0.002588}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002588, "profit_usd": 0.047412, "profit_margin_pct": 94.82, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 8.25}}
{"timestamp": "2025-12-30T22:08:20.321699", "claim": "Does light have mass?", "verdict": "Unverified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3038, "total_output": 416, "prover": {"model": "gemini-2.0-flash-exp", "input": 798, "output": 81}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 775, "output": 105}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1465, "output": 230}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.000325, "judge_cost": 0.002615, "total_cost": 0.00294}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.00294, "profit_usd": 0.04706, "profit_margin_pct": 94.12, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 9.21}}
{"timestamp": "2025-12-30T22:08:20.527668", "claim": "Is democracy a failed system?", "verdict": "Inconclusive", "confidence_score": 0.3, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 0, "total_output": 0, "prover": {"input": 0, "output": 0, "model": "N/A"}, "debunker": {"input": 0, "output": 0, "model": "N/A"}, "judge": {"input": 0, "output": 0, "model": "N/A"}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.0, "total_cost": 0.0}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.0, "profit_usd": 0.0, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 0, "execution_time_sec": 0.0}}
{"timestamp": "2025-12-30T22:08:30.842581", "claim": "Will CRISPR eliminate genetic diseases by 2035?", "verdict": "Uncertain", "confidence_score": 0.62, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3202, "total_output": 452, "prover": {"model": "gemini-2.0-flash-exp", "input": 905, "output": 113}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 901, "output": 106}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1396, "output": 233}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002561, "total_cost": 0.002561}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002561, "profit_usd": 0.047439, "profit_margin_pct": 94.88, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 10.11}}
{"timestamp": "2025-12-30T22:08:42.132992", "claim": "Is 'rizz' actually a real word or just internet slang?", "verdict": "Inconclusive", "confidence_score": 0.25, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 3124, "total_output": 506, "prover": {"model": "gemini-2.0-flash-exp", "input": 823, "output": 78}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 788, "output": 123}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1513, "output": 305}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.000348, "judge_cost": 0.003038, "total_cost": 0.003386}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.003386, "profit_usd": -0.003386, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 11.09}}
{"timestamp": "2025-12-30T22:08:42.337954", "claim": "Does pineapple belong on pizza?", "verdict": "Inconclusive", "confidence_score": 0.3, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 0, "total_output": 0, "prover": {"input": 0, "output": 0, "model": "N/A"}, "debunker": {"input": 0, "output": 0, "model": "N/A"}, "judge": {"input": 0, "output": 0, "model": "N/A"}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.0, "total_cost": 0.0}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.0, "profit_usd": 0.0, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 0, "execution_time_sec": 0.0}}
{"timestamp": "2025-12-30T22:08:42.542987", "claim": "Does religion cause more harm than good?", "verdict": "Inconclusive", "confidence_score": 0.3, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 0, "total_output": 0, "prover": {"input": 0, "output": 0, "model": "N/A"}, "debunker": {"input": 0, "output": 0, "model": "N/A"}, "judge": {"input": 0, "output": 0, "model": "N/A"}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.0, "total_cost": 0.0}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.0, "profit_usd": 0.0, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 0, "execution_time_sec": 0.0}}
{"timestamp": "2025-12-30T22:08:51.622795", "claim": "Will AGI be achieved before 2030?", "verdict": "Uncertain", "confidence_score": 0.45, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3267, "total_output": 407, "prover": {"model": "gemini-2.0-flash-exp", "input": 953, "output": 102}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 949, "output": 87}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1365, "output": 218}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002455, "total_cost": 0.002455}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002455, "profit_usd": 0.047545, "profit_margin_pct": 95.09, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 8.88}}
{"timestamp": "2025-12-30T22:09:02.920207", "claim": "Is 'bussin' a valid replacement for 'delicious'?", "verdict": "Verified", "confidence_score": 0.75, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3176, "total_output": 479, "prover": {"model": "gemini-2.0-flash-exp", "input": 853, "output": 110}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 784, "output": 114}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1539, "output": 255}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.000337, "judge_cost": 0.002814, "total_cost": 0.003151}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003151, "profit_usd": 0.046849, "profit_margin_pct": 93.7, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 11.09}}
{"timestamp": "2025-12-30T22:09:16.251594", "claim": "Does free will exist?", "verdict": "Uncertain", "confidence_score": 0.55, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 2627, "total_output": 396, "prover": {"model": "gemini-2.0-flash-exp", "input": 741, "output": 77}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 737, "output": 86}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1149, "output": 233}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002314, "total_cost": 0.002314}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002314, "profit_usd": 0.047686, "profit_margin_pct": 95.37, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 13.13}}
{"timestamp": "2025-12-30T22:09:27.825911", "claim": "Does the government control the weather?", "verdict": "Unverified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3123, "total_output": 440, "prover": {"model": "gemini-2.0-flash-exp", "input": 825, "output": 74}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 805, "output": 109}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1493, "output": 257}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.000337, "judge_cost": 0.002778, "total_cost": 0.003115}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003115, "profit_usd": 0.046885, "profit_margin_pct": 93.77, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 11.37}}
{"timestamp": "2025-12-30T22:09:37.904013", "claim": "Is cold fusion scientifically achievable?", "verdict": "Unverified", "confidence_score": 0.75, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3662, "total_output": 424, "prover": {"model": "gemini-2.0-flash-exp", "input": 1015, "output": 78}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 1036, "output": 81}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1611, "output": 265}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002936, "total_cost": 0.002936}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002936, "profit_usd": 0.047064, "profit_margin_pct": 94.13, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 9.88}}
{"timestamp": "2025-12-30T22:10:15.425717", "claim": "Is calling someone a 'CEO' actually a compliment?", "verdict": "Unverified", "confidence_score": 0.65, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 2856, "total_output": 451, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 690, "output": 99}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 741, "output": 112}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1425, "output": 240}}, "costs": {"prover_cost": 0.000485, "debunker_cost": 0.000323, "judge_cost": 0.002625, "total_cost": 0.003434}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003434, "profit_usd": 0.046566, "profit_margin_pct": 93.13, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 37.32}}
{"timestamp": "2025-12-30T22:10:26.529487", "claim": "Does art need to have meaning?", "verdict": "Inconclusive", "confidence_score": 0.35, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 3510, "total_output": 549, "prover": {"model": "gemini-2.0-flash-exp", "input": 936, "output": 128}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 957, "output": 103}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1617, "output": 318}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.003207, "total_cost": 0.003207}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.003207, "profit_usd": -0.003207, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 10.9}}
{"timestamp": "2025-12-30T22:10:37.705271", "claim": "Are all politicians corrupt?", "verdict": "Unverified", "confidence_score": 0.75, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3323, "total_output": 499, "prover": {"model": "gemini-2.0-flash-exp", "input": 911, "output": 116}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 850, "output": 120}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1562, "output": 263}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.000362, "judge_cost": 0.002877, "total_cost": 0.003239}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003239, "profit_usd": 0.046762, "profit_margin_pct": 93.52, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 10.97}}
{"timestamp": "2025-12-30T22:10:46.862965", "claim": "Is P = NP likely to be proven true?", "verdict": "Uncertain", "confidence_score": 0.25, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 3388, "total_output": 424, "prover": {"model": "gemini-2.0-flash-exp", "input": 978, "output": 71}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 974, "output": 104}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1436, "output": 249}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002681, "total_cost": 0.002681}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.002681, "profit_usd": -0.002681, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 8.95}}
{"timestamp": "2025-12-30T22:11:22.598006", "claim": "Is 'cap' the same as 'no cap' or are they opposites?", "verdict": "Verified", "confidence_score": 0.85, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3242, "total_output": 539, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 800, "output": 125}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 832, "output": 133}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1610, "output": 281}}, "costs": {"prover_cost": 0.000571, "debunker_cost": 0.000371, "judge_cost": 0.003015, "total_cost": 0.003957}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003957, "profit_usd": 0.046043, "profit_margin_pct": 92.09, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 35.53}}
{"timestamp": "2025-12-30T22:11:31.950953", "claim": "Does money buy happiness?", "verdict": "Verified", "confidence_score": 0.75, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 2929, "total_output": 430, "prover": {"model": "gemini-2.0-flash-exp", "input": 753, "output": 85}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 774, "output": 98}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1402, "output": 247}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002637, "total_cost": 0.002637}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002637, "profit_usd": 0.047363, "profit_margin_pct": 94.73, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 9.15}}
{"timestamp": "2025-12-30T22:11:42.639393", "claim": "Are vaccines more dangerous than the diseases they prevent?", "verdict": "Verified", "confidence_score": 0.95, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 2750, "total_output": 432, "prover": {"model": "gemini-2.0-flash-exp", "input": 701, "output": 80}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 701, "output": 100}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1348, "output": 252}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.000299, "judge_cost": 0.002608, "total_cost": 0.002907}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002907, "profit_usd": 0.047093, "profit_margin_pct": 94.19, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 10.48}}
{"timestamp": "2025-12-30T22:11:52.740181", "claim": "Does SHA-256 have known collision vulnerabilities?", "verdict": "Unverified", "confidence_score": 0.65, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3609, "total_output": 463, "prover": {"model": "gemini-2.0-flash-exp", "input": 993, "output": 105}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 1014, "output": 114}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1602, "output": 244}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002822, "total_cost": 0.002822}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002822, "profit_usd": 0.047178, "profit_margin_pct": 94.36, "inconclusive_penalty": false}, "metadata": {"search_count": 5, "execution_time_sec": 9.9}}
{"timestamp": "2025-12-30T22:12:34.284445", "claim": "Does light have mass?", "verdict": "Inconclusive", "confidence_score": 0.5, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3022, "total_output": 438, "prover": {"model": "gemini-2.0-flash-exp", "input": 775, "output": 67}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 796, "output": 103}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1451, "output": 268}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.002791, "total_cost": 0.002791}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002791, "profit_usd": 0.047209, "profit_margin_pct": 94.42, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 10.01}}
{"timestamp": "2025-12-30T22:12:34.489902", "claim": "Is democracy a failed system?", "verdict": "Inconclusive", "confidence_score": 0.3, "is_inconclusive": true, "was_refunded": true, "tokens": {"total_input": 0, "total_output": 0, "prover": {"input": 0, "output": 0, "model": "N/A"}, "debunker": {"input": 0, "output": 0, "model": "N/A"}, "judge": {"input": 0, "output": 0, "model": "N/A"}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.0, "total_cost": 0.0}, "economics": {"revenue_usdc": 0.0, "total_cost_usd": 0.0, "profit_usd": 0.0, "profit_margin_pct": -100, "inconclusive_penalty": true}, "metadata": {"search_count": 0, "execution_time_sec": 0.0}}
{"timestamp": "2025-12-30T22:12:45.881332", "claim": "Will CRISPR eliminate genetic diseases by 2035?", "verdict": "Uncertain", "confidence_score": 0.45, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 3033, "total_output": 505, "prover": {"model": "gemini-2.0-flash-exp", "input": 871, "output": 122}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 783, "output": 105}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1379, "output": 278}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.000327, "judge_cost": 0.002769, "total_cost": 0.003096}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.003096, "profit_usd": 0.046904, "profit_margin_pct": 93.81, "inconclusive_penalty": true}, "metadata": {"search_count": 5, "execution_time_sec": 11.19}}
{"timestamp": "2026-01-01T17:06:15.821717", "claim": "Bitcoin was invented in 2009", "verdict": "Verified", "confidence_score": 0.95, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 4850, "total_output": 370, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 1200, "output": 150}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 1150, "output": 140}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 2500, "output": 80}}, "costs": {"prover_cost": 0.000826, "debunker_cost": 0.000465, "judge_cost": 0.0029, "total_cost": 0.004191}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.004191, "profit_usd": 0.045809, "profit_margin_pct": 91.62, "inconclusive_penalty": false}, "metadata": {"search_count": 10, "execution_time_sec": 8.5}}
{"timestamp": "2026-01-01T17:06:15.822217", "claim": "The sky is blue", "verdict": "Verified", "confidence_score": 0.98, "is_inconclusive": false, "was_refunded": false, "tokens": {"total_input": 3350, "total_output": 250, "prover": {"model": "meta-llama/Llama-3.3-70B-Instruct-Turbo", "input": 800, "output": 100}, "debunker": {"model": "deepseek-ai/DeepSeek-V3", "input": 750, "output": 90}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 1800, "output": 60}}, "costs": {"prover_cost": 0.000551, "debunker_cost": 0.000302, "judge_cost": 0.0021, "total_cost": 0.002952}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.002952, "profit_usd": 0.047048, "profit_margin_pct": 94.1, "inconclusive_penalty": false}, "metadata": {"search_count": 8, "execution_time_sec": 6.2}}
{"timestamp": "2026-01-01T17:06:15.822217", "claim": "Will it rain tomorrow in New York?", "verdict": "Uncertain", "confidence_score": 0.65, "is_inconclusive": true, "was_refunded": false, "tokens": {"total_input": 6100, "total_output": 480, "prover": {"model": "gemini-2.0-flash-exp", "input": 1500, "output": 200}, "debunker": {"model": "gemini-2.0-flash-exp", "input": 1400, "output": 180}, "judge": {"model": "claude-3-5-haiku-20241022", "input": 3200, "output": 100}}, "costs": {"prover_cost": 0.0, "debunker_cost": 0.0, "judge_cost": 0.0037, "total_cost": 0.0037}, "economics": {"revenue_usdc": 0.05, "total_cost_usd": 0.0037, "profit_usd": 0.0463, "profit_margin_pct": 92.6, "inconclusive_penalty": true}, "metadata": {"search_count": 12, "execution_time_sec": 12.3}}
